package pomdp.algorithms.pointbased;

import java.util.List;
import java.util.Map;
import java.util.Vector;

import pomdp.algorithms.ValueIteration;
import pomdp.environments.POMDP;
import pomdp.integral.Beta;
import pomdp.utilities.AlphaVector;
import pomdp.utilities.BeliefState;
import pomdp.utilities.ExecutionProperties;
import pomdp.utilities.JProf;
import pomdp.utilities.Logger;
import pomdp.utilities.Pair;
import pomdp.utilities.datastructures.LinkedList;
import pomdp.utilities.distribution.DistributionCalculator;
import pomdp.valuefunction.JigSawValueFunction;
import pomdp.valuefunction.LinearValueFunctionApproximation;
import pomdp.valuefunction.MDPValueFunction;

public class HeuristicSearchValueIteration extends ValueIteration {
	protected JigSawValueFunction m_vfUpperBound;
	protected int m_cApplyHComputations;
	protected int m_cNewPointComputations;
	protected int m_cVisitedBeliefStates;
	protected double m_dMaxWidthForIteration;
	private static double m_dExplorationFactor;
	
	private String algorithmName;
	private DistributionCalculator calculator;
	
	public HeuristicSearchValueIteration( POMDP pomdp, double dExplorationFactor, boolean bUseFIB  ){
		super( pomdp );
		
		
		if( !m_vfMDP.persistQValues() ){
			m_vfMDP = new MDPValueFunction( pomdp, 0.0 );
			m_vfMDP.persistQValues( true );
			m_vfMDP.valueIteration( 100, m_dEpsilon );
		}
		m_vfUpperBound = new JigSawValueFunction( pomdp, m_vfMDP, bUseFIB );
		m_cNewPointComputations = 0;
		m_cApplyHComputations = 0;
		m_cVisitedBeliefStates = 0;
		m_dMaxWidthForIteration = 0.0;
		m_dExplorationFactor = dExplorationFactor;
	}
	public HeuristicSearchValueIteration( POMDP pomdp, boolean bUseFIB ){
		this( pomdp, 0.0, bUseFIB );
	}
	
	public void setAlgorithmName(String algorithmName) {
		this.algorithmName = algorithmName;
	}
	
	public String getAlgorithmName() {
		return this.algorithmName;
	}

	/**
	 * 更新上界
	 * @param bs 信念状态点b
	 */
	protected void applyH( BeliefState bs ){
		long lTimeBefore = 0, lTimeAfter = 0;
		
		if( ExecutionProperties.getReportOperationTime() )
			lTimeBefore = JProf.getCurrentThreadCpuTimeSafe();
	
		m_vfUpperBound.updateValue( bs );
		
		if( ExecutionProperties.getReportOperationTime() ){
			lTimeAfter = JProf.getCurrentThreadCpuTimeSafe();
			
			m_cTimeInHV += ( lTimeAfter - lTimeBefore ) / 1000000;
		}
	}

	public int getAction( BeliefState bsCurrent ){
		AlphaVector avMaxAlpha = m_vValueFunction.getMaxAlpha( bsCurrent );
		return avMaxAlpha.getAction();
	}
	
	protected String toString( double[][] adArray ){
		int i = 0, j = 0;
		String sRes = "";
		for( i = 0 ; i < adArray.length ; i++ ){
			for( j = 0 ; j < adArray[i].length ; j++ ){
				sRes += adArray[i][j] + " ";
			}
			sRes += "\n";
		}
		return sRes;
	}

	/**
	 * 计算excess uncertainty：excess(b, t) = width(V^(b)) - εγ^-t
	 * @param bsCurrent 信念状态b
	 * @param dEpsilon ε
	 * @param dDiscount 折扣γ^t
	 * @return excess uncertainty
	 */
	protected double excess( BeliefState bsCurrent, double dEpsilon, double dDiscount ){
		return width( bsCurrent ) - ( dEpsilon / dDiscount );
	}

	/**
	 * width(V^(b)) = V上界(b) - V下界(b)
	 * @param bsCurrent 信念状态b
	 * @return width(V^(b))
	 */
	protected double width( BeliefState bsCurrent ){
		double dUpperValue = 0.0, dLowerValue = 0.0, dWidth = 0.0;
		//V上界(b)
		dUpperValue = m_vfUpperBound.valueAt( bsCurrent );
		//V下界(b)
		dLowerValue = valueAt( bsCurrent );
		dWidth = dUpperValue - dLowerValue;	
		
		return dWidth;
	}
		
	public String getName(){
		if (algorithmName == null) {
			return "HSVI";
		}
		else {
			return "HSVI"+"_"+algorithmName;
		}
	}

	/**
	 * π = HSVI(ε)
	 * 1. 初始化上界m_vfUpperBound和下界m_vValueFunction，
	 *    上界在HeuristicSearchValueIteration的构造函数中初始化，下界在父类ValueIteration中初始化
	 * 2. 循环执行explore
	 *    结束条件：循环超出指定次数 || 达到终止条件（超出时间）
	 *    在循环中，若上界函数的点的个数超过1000 && 两次迭代之间上界函数的点的个数增长超过10%; 对上界函数进行裁剪
	 *    下界函数的剪枝是在每次加入新向量时完成
	 * @param cIterations 迭代次数
	 * @param dEpsilon ε
	 * @param dTargetValue 希望达到的回报
	 * @param maxRunningTime 最大运行时间
	 * @param numEvaluations （没用到）
	 */
	public void valueIteration(int cIterations, double dEpsilon, double dTargetValue, int maxRunningTime, int numEvaluations)
	{
		// 初始化各种变量
		// 初始信念点
		BeliefState bsInitial = m_pPOMDP.getBeliefStateFactory().getInitialBeliefState();
		// 初始信念点宽度
		double dInitialWidth = width( bsInitial );

		// 遍历计数器 / 最大explore深度
		int iIteration = 0, iMaxDepth = 0;

		// 时间变量
		long lStartTime = System.currentTimeMillis(), lCurrentTime = 0;

		// 运行环境
		Runtime rtRuntime = Runtime.getRuntime();

		// 控制循环终止的变量
		boolean bDone = false;

		// 记录迭代中计算的ADR
		Pair<Double, Double> pComputedADRs = new Pair<Double, Double>();

		//观测到的信念点
		Vector<BeliefState> vObservedBeliefStates = new Vector<BeliefState>();
		int cUpperBoundPoints = 0, cNoChange = 0;
		String sMsg = "";

		m_cElapsedExecutionTime = 0;
		m_cCPUExecutionTime = 0;

		//计算时间
		long lCPUTimeBefore = 0, lCPUTimeAfter = 0, lCPUTimeTotal = 0;

		int cValueFunctionChanges = 0;

		//最大执行时间，默认设置为10分钟
		long maxExecutionTime = m_maxExecutionTime;//1000*60*10;

		Logger.getInstance().logln( "Begin " + getName() + ", Initial width = " + dInitialWidth );
		
		// 循环主体
		// 结束条件：循环超出指定次数 || 达到终止条件（超出时间）
		for( iIteration = 0 ; ( iIteration < cIterations ) && !bDone && !m_bTerminate ; iIteration++ ){
			// 获取迭代开始的时间戳
			lStartTime = System.currentTimeMillis();
			lCPUTimeBefore = JProf.getCurrentThreadCpuTimeSafe();
			
			// 记录迭代的最大宽度
			m_dMaxWidthForIteration = 0.0;
			
			// explore的主体过程;返回explore的最大深度
			iMaxDepth = explore( bsInitial, dEpsilon, 0, 1.0, vObservedBeliefStates );
			
			// 若上界函数的点的个数超过1000 && 两次迭代之间上界函数的点的个数增长超过10%; 对上界函数进行裁剪。
			if( ( m_vfUpperBound.getUpperBoundPointCount() > 1000 ) && ( m_vfUpperBound.getUpperBoundPointCount() > cUpperBoundPoints * 1.1 ) ){
				// 裁剪过程：去掉上界函数中，函数值和初始值的差小于epsilon的点
				m_vfUpperBound.pruneUpperBound();
				cUpperBoundPoints = m_vfUpperBound.getUpperBoundPointCount();
			}
			
			// 累计explore深度
			m_cVisitedBeliefStates += iMaxDepth;
			
			// 重新计算b0点的width
			dInitialWidth = width( bsInitial );			
			
			//计算时间
			lCurrentTime = System.currentTimeMillis();
			lCPUTimeAfter = JProf.getCurrentThreadCpuTimeSafe();
			m_cElapsedExecutionTime += ( lCurrentTime - lStartTime );
			m_cCPUExecutionTime += ( lCPUTimeAfter - lCPUTimeBefore ) / 1000000;
			lCPUTimeTotal += lCPUTimeAfter - lCPUTimeBefore;
			
			//如果maxExecutionTime > 0 而且总时间超过maxExecutionTime;终止迭代
			if (maxExecutionTime > 0) {
				bDone = (m_cElapsedExecutionTime > maxExecutionTime);
			}
			
			// 每5次且下界函数发生变化时，计算ADR
			if( ( iIteration >= 5 ) && ( ( lCPUTimeTotal  / 1000000000 ) >= 0 ) && ( iIteration % 5 == 0 ) && m_vValueFunction.getChangesCount() > cValueFunctionChanges ){
				//原始算法;计算ADR的值是否大于给定值，如果是则算是收敛			
				//bDone = checkADRConvergence( m_pPOMDP, dTargetValue, pComputedADRs );
				//不把这个条件作为终止迭代的条件
				checkADRConvergence( m_pPOMDP, dTargetValue, pComputedADRs );
				
				// 记录本次下界函数的变化值
				cValueFunctionChanges = m_vValueFunction.getChangesCount();
				
				//显式调用 垃圾回收
				rtRuntime.gc();
				
				//输出消息
				sMsg = getName() + ": Iteration " + iIteration + 
									" initial width " + round( dInitialWidth, 3 ) +
									" V(b) " + round( m_vValueFunction.valueAt( m_pPOMDP.getBeliefStateFactory().getInitialBeliefState() ), 4 ) +
									" V^(b) " + round( m_vfUpperBound.valueAt( m_pPOMDP.getBeliefStateFactory().getInitialBeliefState() ), 4 ) +
									//" max width bs = " + bsMaxWidth + 
									//" max width " + round( width( bsMaxWidth ), 3 ) +
									" max depth " + iMaxDepth +
									" max width " + round( m_dMaxWidthForIteration, 3 ) +
									//" simulated ADR " + ((Number) pComputedADRs.first()).doubleValue() +
									//" filtered ADR " + round( ((Number) pComputedADRs.second()).doubleValue(), 3 ) +
									" Time " + ( lCurrentTime - lStartTime ) / 1000 +
									" CPU time " + ( lCPUTimeAfter - lCPUTimeBefore ) / 1000000000 +
									" CPU total " + lCPUTimeTotal  / 1000000000 +
									" |V| " + m_vValueFunction.size() +
									" |V^| " + m_vfUpperBound.getUpperBoundPointCount() +
									" V changes " + m_vValueFunction.getChangesCount() +
									" #ObservedBS = " + vObservedBeliefStates.size() +
									" #BS " + m_pPOMDP.getBeliefStateFactory().getBeliefUpdatesCount() +
									" #backups " + m_cBackups +
									" #V^(b) = " + m_cNewPointComputations +
									" max depth " + iMaxDepth +
									" free memory " + rtRuntime.freeMemory() / 1000000 +
									" total memory " + rtRuntime.totalMemory() / 1000000 +
									" max memory " + rtRuntime.maxMemory() / 1000000;
			}
			else{
				//输出消息
				sMsg = getName() + ": Iteration " + iIteration + 
						" initial width " + round( dInitialWidth, 3 ) +
						" V(b) " + round( m_vValueFunction.valueAt( m_pPOMDP.getBeliefStateFactory().getInitialBeliefState() ), 4 ) +
						" V^(b) " + round( m_vfUpperBound.valueAt( m_pPOMDP.getBeliefStateFactory().getInitialBeliefState() ), 4 ) +
						" max depth " + iMaxDepth +
						" max width " + round( m_dMaxWidthForIteration, 3 ) +
						" Time " + ( lCurrentTime - lStartTime ) / 1000 +
						" CPU time " + ( lCPUTimeAfter - lCPUTimeBefore ) / 1000000000 +
						" CPU total " + lCPUTimeTotal  / 1000000000 +
						" |V| " + m_vValueFunction.size() +
						" |V^| " + m_vfUpperBound.getUpperBoundPointCount() +
						" #ObservedBS = " + vObservedBeliefStates.size() +
						" #BS " + m_pPOMDP.getBeliefStateFactory().getBeliefUpdatesCount() +
						" #backups " + m_cBackups +
						" #V^(b) = " + m_cNewPointComputations +
						" #HV(B) = " + m_cApplyHComputations +
						" free memory " + rtRuntime.freeMemory() / 1000000 +
						" total memory " + rtRuntime.totalMemory() / 1000000 +
						" max memory " + rtRuntime.maxMemory() / 1000000 + 
						"\t";
			}
			Logger.getInstance().log( getName(), 0, "VI", sMsg );
			Logger.getInstance().logln();
			
			//记录下界函数不发生变化的次数
			if( m_vValueFunction.getChangesCount() == cValueFunctionChanges ){
				cNoChange++;
			}
			//发生变化则置零
			else
				cNoChange = 0;
		}
		
		m_cElapsedExecutionTime /= 1000;
		m_cCPUExecutionTime /= 1000;
		
		//输出完成的信息
		sMsg = "Finished " + getName() + " - time : " + m_cElapsedExecutionTime +
				" |V| = " + m_vValueFunction.size() + 
				" backups = " + m_cBackups + 
				" GComputations = " + AlphaVector.getGComputationsCount() +
				" #V^(b) = " + m_cNewPointComputations +
				" Dot products = " + AlphaVector.dotProductCount();
		Logger.getInstance().log( "HSVI", 0, "VI", sMsg );
		
		if( ExecutionProperties.getReportOperationTime() ){
			sMsg = "Avg time: backup " + ( m_cTimeInBackup / ( m_cBackups * 1.0 ) ) + 
					" G " + AlphaVector.getAvgGTime() +
					" Tau " + m_pPOMDP.getBeliefStateFactory().getAvgTauTime() + 
					" DP " + AlphaVector.getAvgDotProductTime() +
					" V^(b) " + ( m_cTimeInV / ( m_cNewPointComputations * 1.0 ) / 1000000 ) + 
					" HV(b) " + ( m_cTimeInHV / ( m_cApplyHComputations * 1.0 ) );
			Logger.getInstance().log( "HSVI", 0, "VI", sMsg );
		}
	}

	// 更新bs点的上下界
	protected void updateBounds( BeliefState bsCurrent ){
		//更新下界
		AlphaVector avNext = backup( bsCurrent );
		AlphaVector avCurrent = m_vValueFunction.getMaxAlpha( bsCurrent );
		double dCurrentValue = valueAt( bsCurrent );
		double dNewValue = avNext.dotProduct( bsCurrent );
		if( dNewValue > dCurrentValue ){
			m_vValueFunction.addPrunePointwiseDominated( avNext );
		}
		//更新上界
		applyH( bsCurrent );
	}


	/**
	 * 获取下一个信念点τ(b, a^*, o^*)
	 * @param bsCurrent b
	 * @param dEpsilon ε
	 * @param dDiscount γ^(t+1)
	 * @return 下一个信念点
	 */
	// explore获取下一个信念点
	protected BeliefState getNextBeliefState( BeliefState bsCurrent, double dEpsilon, double dDiscount ){
		//获取最优的action
		int iAction = getExplorationAction( bsCurrent );
		
		//根据action获取最优的观测
		int iObservation = getExplorationObservation( bsCurrent, iAction, dEpsilon, dDiscount );
		
		if( iObservation == -1 ){
			return null;
		}
		
		return bsCurrent.nextBeliefState( iAction, iObservation );		
	}

	/**
	 * explore(b, ε, t)
	 * 1.深度大于200或者宽度小于阈值（epsilon/pow(gama,t))返回
	 * 2.获得下一个信念点，其中包含了选择动作和选择观察
	 * 3.调用explore(b',ε,t+1)
	 * 4.在信念状态点b上 更新 上下界值函数
	 * @param bsCurrent 信念状态b
	 * @param dEpsilon ε
	 * @param iTime 该函数的调用次数
	 * @param dDiscount γ^(t+1)
	 * @param vObservedBeliefStates 已经访问过的信念状态点
	 * @return 在信念状态生成树中探索的深度t
	 */
	//explore过程
	protected int explore( BeliefState bsCurrent, double dEpsilon, int iTime, double dDiscount, Vector<BeliefState> vObservedBeliefStates ){
		//初始化各种变量
		double dWidth = width( bsCurrent );
		int iAction = 0, iObservation = 0;
		BeliefState bsNext = null;
		int iMaxDepth = 0;

		if( m_bTerminate )
			return iTime;
		
		// 如果bs点之前没有explore过，添加到ObservedBeliefStates点集合。
		if( !vObservedBeliefStates.contains( bsCurrent ) )
			vObservedBeliefStates.add( bsCurrent );
		
		// 记录最大width
		if( dWidth > m_dMaxWidthForIteration )
			m_dMaxWidthForIteration = dWidth;
		
		// 深度大于200或者宽度小于阈值（epsilon/pow(gama,t))
		if( iTime > 200 || dWidth < ( dEpsilon / dDiscount ) )
			return iTime;
		
		// 获得下一个信念点
		bsNext = getNextBeliefState( bsCurrent, dEpsilon, dDiscount * m_dGamma );

		// 下一信念点不为空 且 不等于当前点；递归进行explore过程
		if( ( bsNext != null ) && ( bsNext != bsCurrent ) ){
			iMaxDepth = explore( bsNext, dEpsilon, iTime + 1, dDiscount * m_dGamma, vObservedBeliefStates );
		}
		else{
			iMaxDepth = iTime;
		}
		
		// 更新当前点的上下界
		updateBounds( bsCurrent );	
		
		
		// 根据随机概率当前点继续explore
		// 默认参数条件下不触发
		if( m_dExplorationFactor > 0.0 ){
			int iActionAfterUpdate = getExplorationAction( bsCurrent );
			if( iActionAfterUpdate != iAction ){
				if( m_rndGenerator.nextDouble() < m_dExplorationFactor ){
					iObservation = getExplorationObservation( bsCurrent, iActionAfterUpdate, dEpsilon, dDiscount );
					bsNext = bsCurrent.nextBeliefState( iAction, iObservation );
					if( bsNext != null ){
						iMaxDepth = explore( bsNext, dEpsilon, iTime + 1, dDiscount * m_dGamma, vObservedBeliefStates );
						updateBounds( bsCurrent );	
					}
				}					
			}
		}
					
		return iMaxDepth;
	}

	/**
	 * 选择观察o^*
	 * @param bsCurrent 信念状态点b
	 * @param iAction 动作a^*
	 * @param dEpsilon ε
	 * @param dDiscount γ^t
	 * @return 所选观察o^*的下标
	 */
	// 获取最优的观测
	protected int getExplorationObservation( BeliefState bsCurrent, int iAction, 
			double dEpsilon, double dDiscount ){
		int iObservation = 0, iMaxObservation = -1;
		double dProb = 0.0, dExcess = 0.0, dValue = 0.0, dMaxValue = 0.0;
		BeliefState bsNext = null;
		
		for( iObservation = 0 ; iObservation < m_cObservations ; iObservation++ ){
			//Pr(o|b,a^*)
			dProb = bsCurrent.probabilityOGivenA( iAction, iObservation );
			if( dProb > 0 ){
				//τ(b, a^*, o) 即b'
				bsNext = bsCurrent.nextBeliefState( iAction, iObservation );
				//excess(τ(b, a^*, o), t+1) 这里的dDiscount为γ^(t+1)
				dExcess = excess( bsNext, dEpsilon, dDiscount );
				//Pr(o|b,a^*) * excess(τ(b, a^*, o), t+1)
				dValue = dProb * dExcess;
				// o* = argmax[ Pr(o|b,a^*) * excess(τ(b, a^*, o), t+1) ]
				if( dValue > dMaxValue ){
					dMaxValue = dValue;
					iMaxObservation = iObservation;
				}
			}
		}
		// o* = argmax[ Pr(o|b,a^*) * excess(τ(b, a^*, o), t+1) ]
		return iMaxObservation;
	}

	/**
	 * 选择动作a^*
	 * @param bsCurrent 信念状态点b
	 * @return 所选动作a^*的下标
	 */
	protected int getExplorationAction( BeliefState bsCurrent ){
		/*原始HSVI算法，根据上界取action*/
//		if (algorithmName == null) {
//			return m_vfUpperBound.getAction( bsCurrent );
//		}
//		
//		/*根据分布取action*/
//		else {
//			return getActionByDistribution(bsCurrent);
//		}
//		long s1 = System.currentTimeMillis();
//		m_vfUpperBound.getAction( bsCurrent );
//		long e1 = System.currentTimeMillis();
//		long t1 = e1-s1;
//		
//		long s2 = System.currentTimeMillis();
//		getActionByDistribution(bsCurrent);
//		long e2 = System.currentTimeMillis();
//		long t2 = e2-s2;
//		
//		System.out.println("dis:"+t2+"\tori:"+t1+"\tdis-ori:"+(t2-t1));
		
		if (algorithmName == null) {
			return m_vfUpperBound.getAction( bsCurrent );
		}
		
		/*根据分布取action*/
		else {
			return getActionByDistribution(bsCurrent);
		}
		
		
	}
	
	private int getActionByDistribution ( BeliefState bs ) {
		/*均匀分布算法*/
		/*做cMaxIteration次试验，每次试验遍历一次所有的action
		 *对action的上界和下届，根据分布取一个随机值
		 *记录取值最大的action,其count+1
		 *在cMaxIteration次试验之后，取count值最大的action 
		 */
		int cMaxIteraiton = 1000;
		double[] upperBounds = new double[m_pPOMDP.getActionCount()];
		double[] lowerBounds = new double[m_pPOMDP.getActionCount()];
		
		for (int iAction = 0; iAction<m_pPOMDP.getActionCount(); iAction++) {
			upperBounds[iAction] = m_vfUpperBound.getValueByAction(bs, iAction);
//			System.out.println("up:"+upperBounds[iAction]);
			//lowerBounds[iAction] = G(iAction, bs, m_vValueFunction).dotProduct(bs);
			lowerBounds[iAction] = getLowerBound(bs, iAction, m_vValueFunction);
//			System.out.println("low:"+lowerBounds[iAction]);
		}
		
		int count[] = new int[m_pPOMDP.getActionCount()];
		for (int i = 0; i<cMaxIteraiton; i++) {
			int maxAction = 0;
			double maxValue = Double.NEGATIVE_INFINITY;
			for (int iAction = 0; iAction<m_pPOMDP.getActionCount(); iAction++) {
				// 均匀分布，上下界取随机值
				double upperBound = upperBounds[iAction];
				double lowerBound = lowerBounds[iAction];
				
				//double iValue = 0.0;
				double iValue = calculator.getValue(upperBound, lowerBound);
				/*if (algorithmName.equalsIgnoreCase("Avg")) {
					iValue = getValueByAverageDistribution(upperBound,lowerBound);
				}
				else if (algorithmName.equalsIgnoreCase("Tri")) {
					iValue = getValueByTriangleDistribution(upperBound, lowerBound);
				}
				else {
					iValue = getValueByBetaDistribution(upperBound, lowerBound);
				}*/
				//double iValue = getValueByTriangleDistribution(upperBound, lowerBound);
				//double iValue = getValueByBetaDistribution(upperBound, lowerBound);
				
				if (iValue>maxValue){
					maxValue = iValue;
					maxAction = iAction;	
				}
			}
			
			count[maxAction]++;
		}
		
		int bestAction = 0;
		int maxCount = 0;
		
		for (int iAction = 0; iAction<m_pPOMDP.getActionCount(); iAction++) {
			if (count[iAction] > maxCount) {
				bestAction = iAction;
				maxCount = count[iAction];
			}
		}
		
		return bestAction;
	}
	
	/**
	 * 根据均匀分布取值
	 * @param upperBound	上界
	 * @param lowerBound	下界
	 * @return
	 */
	/*private double getValueByAverageDistribution(double upperBound, double lowerBound) {
		double width = upperBound - lowerBound;
		return m_rndGenerator.nextDouble(width) + lowerBound;
	}
	
	*//**
	 * 根据三角分布取值
	 * @param upperBound	上界
	 * @param lowerBound	下界
	 * @return
	 *//*
	private double getValueByTriangleDistribution(double upperBound, double lowerBound) {
		double width = upperBound - lowerBound;
		double rand_x = m_rndGenerator.nextDouble();
		
		//三角分布函数为f(x)=2x,F(x)=pow(x,2), E(X)=2/3
//		return Math.pow(rand_x, 2) * width + lowerBound;
		
		//三角分布函数为f(x)=2-2x, F(x) = 2x-pow(x,2) ,E(X)=1/3
		return (2*rand_x - Math.pow(rand_x, 2)) * width + lowerBound;
	}
	
	*//**
	 * 根据ｂｅｔａ分布取值，参数a=1,b=3
	 * @param upperBound	上界
	 * @param lowerBound	下界
	 * @return
	 *//*
	private double getValueByBetaDistribution(double upperBound, double lowerBound) {
		Beta b = new Beta();
		double width = upperBound - lowerBound;
		double rand_x = m_rndGenerator.nextDouble();
		return b.calculateBeta(1, 3, 0, rand_x)*width + lowerBound;
	}*/
	
	//获取当前信念点的下界值。
	//代码来自backup过程
	private double getLowerBound(BeliefState bs, int iAction, LinearValueFunctionApproximation vValueFunction) {
		// 初始化各种值。
		/*AlphaVector avMax = null, avG = null, avSum = null;
		List<AlphaVector> vVectors = new LinkedList<AlphaVector>(vValueFunction.getVectors());
		double dMaxValue = MIN_INF, dValue = 0, dProb = 0.0;
		
		// 遍历所有的观测，
		for(int iObservation = 0 ; iObservation < m_cObservations ; iObservation++ ){
			dProb = bs.probabilityOGivenA( iAction, iObservation );
			if( dProb > 0.0 ){
				//dMaxValue = MIN_INF;
				//argmax_i g^i_a,o \cdot b
				//计算每个向量的回报值，取回报最大的向量的点乘结果。
				// 即下界
				for( AlphaVector avAlpha : vVectors ){
					if( avAlpha != null ){
						avG = avAlpha.G( iAction, iObservation );
						
						dValue = avG.dotProduct( bs );
						if( ( avMax == null ) || ( dValue >= dMaxValue ) ){
							dMaxValue = dValue;
							avMax = avG;
						}
					}
				}
			}
		}
		return dMaxValue;*/
		AlphaVector[] aNext = new AlphaVector[m_cObservations];
		return findMaxAlphas(iAction, bs, vValueFunction, aNext);
	}
	
	
	public class ValueFunctionEntry{
		private double m_dValue;
		private int m_iAction;
		private double[] m_adQValues;
		private int m_cActions;
		
		public ValueFunctionEntry( double dValue, int iAction ){
			m_dValue = dValue;
			m_iAction = iAction;
			m_cActions = m_pPOMDP.getActionCount();
			m_adQValues = new double[m_cActions];
			for( iAction = 0 ; iAction < m_cActions ; iAction++ ){
				m_adQValues[iAction] = Double.POSITIVE_INFINITY;
			}
		}
		public void setValue( double dValue ){
			m_dValue = dValue;
		}
		public double getValue(){
			return m_dValue;
		}
		public void setAction( int iAction ){
			m_iAction = iAction;
		}
		public int getAction(){
			return m_iAction;
		}
		public void setQValue( int iAction, double dValue ){
			m_adQValues[iAction] = dValue;
		}
		public double getQValue( int iAction ){
			return m_adQValues[iAction];
		}
		public double getMaxQValue(){
			double dMaxValue = Double.NEGATIVE_INFINITY;
			int iAction = 0;
			for( iAction = 0 ; iAction < m_cActions ; iAction++ ){
				if( m_adQValues[iAction] > dMaxValue )
					dMaxValue = m_adQValues[iAction];
			}
			return dMaxValue;
		}
		public int getMaxAction(){
			double dMaxValue = Double.NEGATIVE_INFINITY;
			int iAction = 0, iMaxAction = -1;
			for( iAction = 0 ; iAction < m_cActions ; iAction++ ){
				if( m_adQValues[iAction] > dMaxValue ){
					dMaxValue = m_adQValues[iAction];
					iMaxAction = iAction;
				}
			}
			return iMaxAction;
		}
	}


	public DistributionCalculator getCalculator() {
		return calculator;
	}
	public void setCalculator(DistributionCalculator calculator) {
		this.calculator = calculator;
	}

}
